{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory notebook\n",
    "The analysis is based on the Gonzalo-Moser EC paper. \n",
    "* 1/28/24 setup\n",
    "* TODO need to separate the awake and sleep epochs\n",
    "* using spikes instead of Ca2+ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os.path import dirname, join\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.fftpack import fft\n",
    "from scipy.stats import zscore\n",
    "\n",
    "sys.path.append(\"/home/gergely/code/sleep/src\")\n",
    "\n",
    "from imaging_data_class import ImagingData\n",
    "from classes.suite2p_class import Suite2p as s2p\n",
    "import imaging_data_class as idc\n",
    "import behavior_class as bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = [\n",
    "    \"140302_3\"\n",
    "]  # [\"5HT2afl05b_1\", \"5HT2afl05b_2\", \"sert52b_1\", \"sert52b_5\", \"sert54a_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = ImagingData(mice[0])\n",
    "mouse.mouse_id\n",
    "s2p_folders = mouse.find_suite2p_folders()\n",
    "for folder in enumerate(s2p_folders):\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_folder = s2p_folders[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_data = s2p(s2p_folder)\n",
    "spikes = s2p_data.get_spikes()\n",
    "# z scoring\n",
    "n_neurons, n_time = spikes.shape\n",
    "spks = zscore(spikes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks_df = pd.DataFrame(spks)\n",
    "plt.plot(spks_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = bc.behaviorData(mouse_id=mice[0])\n",
    "behavior_folders = [\n",
    "    (index, folder) for index, folder in enumerate(behavior.find_behavior_folders())\n",
    "]\n",
    "behavior_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_folder_to_load = 10\n",
    "behavior_file = \"140302_3_20231222154006_910_sleep.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_behavior = behavior_folders[beh_folder_to_load][1]\n",
    "\n",
    "if not dirname(processed_behavior) == dirname(s2p_folder):\n",
    "    raise ValueError(\"Behavior and imaging data folders do not match\")\n",
    "\n",
    "try:\n",
    "    with open(join(processed_behavior, behavior_file), \"r\") as f:\n",
    "        beh = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(processed_behavior, \"filtered_velocity.json\"), \"r\") as f:\n",
    "    speed = np.array(json.load(f))\n",
    "\n",
    "position = np.array(beh[0][\"data\"][\"treadmillPosition\"])\n",
    "\n",
    "with open(join(processed_behavior, \"mobility_immobility.json\"), \"r\") as f:\n",
    "    mob_immob = np.array(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_spks = pd.DataFrame(spks[:, mob_immob == 1])\n",
    "notmoving_spks = pd.DataFrame(spks[:, ~mob_immob == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcluates and plots the autocorrelation of the traces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks_df = notmoving_spks\n",
    "autocorrelations = []\n",
    "max_lag_positions = []\n",
    "# Iterate over each row (each signal trace)\n",
    "for index, row in spks_df.iterrows():\n",
    "    # Convert the row to a NumPy array\n",
    "    data = row.values\n",
    "\n",
    "    # Compute the autocorrelation\n",
    "    autocorr = np.correlate(data, data, mode=\"full\")\n",
    "    autocorr /= np.max(autocorr)  # Normalize\n",
    "    autocorr = autocorr[len(autocorr) // 2 :]  # Take the second half\n",
    "    autocorrelations.append(autocorr[:500])\n",
    "\n",
    "    # Exclude the first lag (lag=0) when finding the max autocorrelation position\n",
    "    max_lag_positions.append(\n",
    "        np.argmax(autocorr[1:]) + 1\n",
    "    )  # +1 to correct for the exclusion\n",
    "# Sort the autocorrelations based on the lag position of the maximum autocorrelation value\n",
    "sorted_indices = np.argsort(max_lag_positions)\n",
    "sorted_autocorr_array = np.array(autocorrelations)[sorted_indices]\n",
    "\n",
    "\n",
    "# Optional: Plot each autocorrelation\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.heatmap(\n",
    "    sorted_autocorr_array, cmap=\"viridis\", cbar_kws={\"label\": \"Autocorrelation\"}\n",
    ")\n",
    "plt.title(\"Autocorrelation Heatmap of Neuronal Spike Data\")\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Signal Trace(Sorted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating PSD of the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming autocorrelations is a list of numpy arrays containing the autocorrelation of each row\n",
    "sampling_frequency = 20  # Sampling frequency in Hz\n",
    "n = len(autocorrelations[0])  # Assuming all autocorrelations have the same length\n",
    "freq_bins = np.fft.fftfreq(n, d=1.0 / sampling_frequency)\n",
    "\n",
    "# Initialize an empty list to store the PSDs\n",
    "psds = []\n",
    "\n",
    "for autocorr in autocorrelations:\n",
    "    psd = np.fft.fft(autocorr)\n",
    "    psd = np.abs(psd) ** 2  # Power spectrum\n",
    "    psds.append(psd[: n // 2])  # Keep only the first half\n",
    "\n",
    "# Convert the list of PSDs into a 2D array\n",
    "psd_array = np.array(psds)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Using seaborn\n",
    "sns.heatmap(\n",
    "    psd_array,\n",
    "    cmap=\"viridis\",\n",
    "    xticklabels=250,\n",
    "    yticklabels=10,\n",
    "    cbar_kws={\"label\": \"Power Spectral Density\"},\n",
    ")\n",
    "plt.xlabel(\"Frequency Bin\")\n",
    "plt.ylabel(\"Signal Trace\")\n",
    "plt.title(\"PSD Heatmap of Autocorrelated Neuronal Spike Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your sampling rate\n",
    "sampling_rate = 20  # Replace with your actual sampling rate\n",
    "\n",
    "# Length of the autocorrelation data\n",
    "N = len(autocorrelations[0])\n",
    "\n",
    "# Calculate the frequency values corresponding to FFT output\n",
    "frequencies = np.fft.fftfreq(N, d=1 / sampling_rate)\n",
    "\n",
    "# Indices for frequencies between 0 and 1 Hz\n",
    "low_freq_indices = np.where((frequencies >= 0) & (frequencies <= 1))[0]\n",
    "\n",
    "psd_list = []\n",
    "for autocorr in autocorrelations:\n",
    "    # Calculate the Fourier Transform\n",
    "    psd = np.abs(fft(autocorr)) ** 2\n",
    "\n",
    "    # Select the PSD components for 0-1 Hz\n",
    "    psd_low_freq = psd[low_freq_indices]\n",
    "\n",
    "    # Z-score normalization\n",
    "    psd_z_scored = zscore(psd_low_freq)\n",
    "    psd_list.append(psd_z_scored)\n",
    "\n",
    "# Sorting based on the maximum power\n",
    "psd_sorted = sorted(psd_list, key=lambda x: np.max(x), reverse=True)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "for psd in psd_sorted:\n",
    "    plt.plot(\n",
    "        frequencies[low_freq_indices], psd\n",
    "    )  # Ensure the x-axis is using the selected frequencies\n",
    "plt.title(\"Sorted Z-scored Power Spectral Densities (0-1 Hz)\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Z-scored PSD\")\n",
    "plt.xlim(0.01, 0.2)  # Set x-axis limit to show only 0 to 1 Hz\n",
    "plt.ylim(-0.2, 10)  # Set y-axis limit to show the PSDs\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your sampling rate\n",
    "sampling_rate = 20  # Replace with your actual sampling rate\n",
    "\n",
    "# Length of the autocorrelation data\n",
    "N = len(autocorrelations[0])\n",
    "\n",
    "# Calculate the frequency values corresponding to FFT output\n",
    "frequencies = np.fft.fftfreq(N, d=1 / sampling_rate)\n",
    "\n",
    "# Indices for frequencies between 0 and 1 Hz\n",
    "low_freq_indices = np.where((frequencies >= 0) & (frequencies <= 5))[0]\n",
    "\n",
    "psd_list = []\n",
    "for autocorr in autocorrelations:\n",
    "    # Calculate the Fourier Transform\n",
    "    psd = np.abs(fft(autocorr)) ** 2\n",
    "\n",
    "    # Select the PSD components for 0-1 Hz\n",
    "    psd_low_freq = psd[low_freq_indices]\n",
    "\n",
    "    # Z-score normalization\n",
    "    psd_z_scored = zscore(psd_low_freq)\n",
    "    psd_list.append(psd_z_scored)\n",
    "\n",
    "# Sorting based on the maximum power\n",
    "psd_sorted = sorted(psd_list, key=lambda x: np.max(x), reverse=True)\n",
    "\n",
    "# Plotting with semilogy\n",
    "plt.figure(figsize=(12, 8))\n",
    "for psd in psd_sorted:\n",
    "    plt.semilogy(\n",
    "        frequencies[low_freq_indices], psd\n",
    "    )  # Use semilogy for logarithmic y-axis\n",
    "plt.title(\"Sorted Z-scored Power Spectral Densities (0-1 Hz)\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Z-scored PSD (log scale)\")\n",
    "plt.xlim(0, 0.1)  # Set x-axis limit to show only 0 to 1 Hz\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given values\n",
    "sampling_frequency = 20  # Hz\n",
    "n = len(autocorrelations[0])  # Length of autocorrelation data\n",
    "\n",
    "# Calculate frequency bins with correct resolution\n",
    "freq_bins = np.fft.fftfreq(n, d=1.0 / sampling_frequency)\n",
    "\n",
    "# Correctly identify indices for positive frequencies\n",
    "positive_freq_indices = np.where(freq_bins > 0)[0]  # Only positive frequencies\n",
    "\n",
    "# Find indices within the specified frequency range\n",
    "min_freq = 0.00\n",
    "max_freq = 0.1\n",
    "desired_freq_indices = np.where((freq_bins >= min_freq) & (freq_bins <= max_freq))[0]\n",
    "\n",
    "# If there are no indices found within the range, this indicates a potential issue\n",
    "if len(desired_freq_indices) == 0:\n",
    "    print(\n",
    "        \"No frequency bins found within the specified range. Consider checking the frequency range or the length of your data.\"\n",
    "    )\n",
    "\n",
    "# Assuming this part is correct, and you have PSDs calculated\n",
    "# Ensure that you only use the positive frequency part for slicing\n",
    "if len(desired_freq_indices) > 0:\n",
    "    sliced_psds = [\n",
    "        psd[desired_freq_indices]\n",
    "        for psd in psds\n",
    "        if len(psd) > max(desired_freq_indices)\n",
    "    ]\n",
    "\n",
    "    if not sliced_psds:\n",
    "        print(\n",
    "            \"Sliced PSDs list is empty. Check if the PSD calculation or slicing went wrong.\"\n",
    "        )\n",
    "    else:\n",
    "        # Continue with plotting as before, ensuring sliced_psds is not empty\n",
    "        print(\"Sliced PSDs ready for plotting.\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(sliced_psds, cmap=\"viridis\", cbar_kws={\"label\": \"Power Spectral Density\"})\n",
    "# Adjust the x-axis to show actual frequency values\n",
    "plt.xticks(\n",
    "    ticks=np.linspace(0, len(desired_freq_indices) - 1, 5),\n",
    "    labels=np.round(np.linspace(min_freq, max_freq, 5), 3),\n",
    ")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Signal Trace\")\n",
    "plt.title(\"PSD Heatmap of Autocorrelated Neuronal Spike Data (0.005 to 0.1 Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
