{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSD analysis if spike data\n",
    "This is based on `psd_analysis.ipynb` in this same directory. \n",
    "\n",
    "* 2/10/2024 setup\n",
    "* 10/30/2024 update using dual plane imaging data. this is also an analysis for an R01 with YP due 11/2024.\n",
    "  * Refactorings\n",
    "* Works as of 10/31/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join, dirname\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import t\n",
    "\n",
    "sys.path.append(\"/home/gergely/code/sleep/\")\n",
    "\n",
    "from src.classes.imaging_data_class import ImagingData\n",
    "from src.classes.suite2p_class import Suite2p as s2p\n",
    "import src.classes.behavior_class as bc\n",
    "from src import frequency_psd as fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mice: \n",
    "\"140502_5\", \"140502_3\", \"5HT2afl05b_1\", \"5HT2afl05b_2\", \"sert52b_1\", \"sert52b_5\", \"sert54a_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sima_folders = [\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11c5/8_2/TSeries-08022024-1036-001/TSeries-08022024-1036-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11c5/8_2/TSeries-08022024-1036-002/TSeries-08022024-1036-002.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b2/6_17/TSeries-06172024-0946-001/TSeries-06172024-0946-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b2/6_17/TSeries-06172024-0946-003/TSeries-06172024-0946-003.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/6_17/TSeries-06172024-0946-001/TSeries-06172024-0946-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/7_31/TSeries-07312024-1030-002/TSeries-07312024-1030-002.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/8_3/TSeries-08022024-1036-001/TSeries-08022024-1036-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/8_3/TSeries-08022024-1036-002/TSeries-08022024-1036-002.sima/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks = {}\n",
    "planes = {0: \"dendrites\", 1: \"soma\"}\n",
    "for folder in sima_folders:\n",
    "    for plane, plane_name in planes.items():\n",
    "        s2p_data = s2p(join(folder, \"suite2p\"))\n",
    "        spikes = s2p_data.get_spikes(plane=plane)\n",
    "        # z scoring\n",
    "        zscored_spikes = zscore(spikes, axis=1)\n",
    "\n",
    "        # Add the z-scored data to the dictionary\n",
    "        if plane_name not in spks:\n",
    "            spks[plane_name] = []  # Initialize a list for each plane\n",
    "        spks[plane_name].append(zscored_spikes)\n",
    "\n",
    "mob_immobs = []\n",
    "for folder in sima_folders:\n",
    "    data = join(folder, \"behavior\", \"mobility_immobility.json\")\n",
    "    with open(data, \"r\") as f:\n",
    "        mob_immobs.append(np.array(json.load(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_immobile_spikes = {}\n",
    "\n",
    "# Assuming `spks` is a dictionary with keys ('dendrites', 'soma') and values being lists of arrays\n",
    "# Assuming `mob_immobs` is a list of mobility data arrays, one for each spike array in `spks`\n",
    "for key, spk_list in spks.items():\n",
    "    moving_spikes_list = []\n",
    "    immobile_spikes_list = []\n",
    "\n",
    "    for spk, mob_immob in zip(spk_list, mob_immobs):\n",
    "        try:\n",
    "            # Convert spk and mob_immob to numpy arrays if they are lists\n",
    "            spk = np.array(spk) if isinstance(spk, list) else spk\n",
    "            mob_immob = (\n",
    "                np.array(mob_immob) if isinstance(mob_immob, list) else mob_immob\n",
    "            )\n",
    "\n",
    "            print(spk.shape, mob_immob.shape)\n",
    "\n",
    "            # Check if shapes are mismatched\n",
    "            if spk.shape[1] != mob_immob.shape[0]:\n",
    "                print(\"shapes mismatched\")\n",
    "\n",
    "                # Create an interpolation function for mob_immob\n",
    "                x = np.linspace(0, 1, mob_immob.shape[0])\n",
    "                f = interp1d(x, mob_immob, kind=\"linear\")\n",
    "\n",
    "                # Create a new x array matching the spk shape and interpolate\n",
    "                new_x = np.linspace(0, 1, spk.shape[1])\n",
    "                mob_immob_interpolated = f(new_x)\n",
    "\n",
    "                # Convert interpolated values to boolean if necessary\n",
    "                mob_immob_interpolated = (\n",
    "                    mob_immob_interpolated >= 0.5\n",
    "                )  # Adjust this threshold as needed\n",
    "            else:\n",
    "                mob_immob_interpolated = mob_immob\n",
    "\n",
    "            # Split spikes into moving and immobile based on mobility data\n",
    "            moving_spikes = spk[:, mob_immob_interpolated == 1]\n",
    "            immobile_spikes = spk[:, mob_immob_interpolated != 1]\n",
    "\n",
    "            # Append the results to the respective lists\n",
    "            moving_spikes_list.append(moving_spikes)\n",
    "            immobile_spikes_list.append(immobile_spikes)\n",
    "\n",
    "        except ValueError as e:  # Adjust exception type if needed\n",
    "            print(f\"Error processing spike and mobility data for key '{key}': {e}\")\n",
    "            # Handle or log the error appropriately\n",
    "\n",
    "    # Store the results in the `moving_immobile_spikes` dictionary\n",
    "    moving_immobile_spikes[key] = {\n",
    "        \"moving_spikes\": moving_spikes_list,\n",
    "        \"immobile_spikes\": immobile_spikes_list,\n",
    "    }\n",
    "\n",
    "# Now `moving_immobile_spikes` contains the keys from the input dictionary `spks`,\n",
    "# with each key having a dictionary of both \"moving_spikes\" and \"immobile_spikes\" lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionaries with lists to store multiple arrays for PSD calculations\n",
    "psd_data = {\n",
    "    key: {\"moving\": {\"freq\": [], \"psd\": []}, \"immobile\": {\"freq\": [], \"psd\": []}}\n",
    "    for key in moving_immobile_spikes.keys()\n",
    "}\n",
    "\n",
    "\n",
    "# Assuming `fp.calculate_psd` is your function to calculate PSD\n",
    "for key, data in moving_immobile_spikes.items():\n",
    "    # Calculate PSD for moving spikes\n",
    "    for mov_data in data[\"moving_spikes\"]:\n",
    "        freq, psd = fp.calculate_psd(mov_data, 30)  # Adjust parameters as needed\n",
    "        psd_data[key][\"moving\"][\"freq\"].append(freq)\n",
    "        psd_data[key][\"moving\"][\"psd\"].append(np.mean(psd, axis=0))\n",
    "\n",
    "    # Calculate PSD for immobile spikes\n",
    "    for imm_data in data[\"immobile_spikes\"]:\n",
    "        freq, psd = fp.calculate_psd(imm_data, 30)  # Adjust parameters as needed\n",
    "        psd_data[key][\"immobile\"][\"freq\"].append(freq)\n",
    "        psd_data[key][\"immobile\"][\"psd\"].append(np.mean(psd, axis=0))\n",
    "\n",
    "# Now `psd_data` contains the PSD information for \"dendrites\" and \"soma\",\n",
    "# separated into \"moving\" and \"immobile\" categories, which can be easily used for plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_psd_to_common_freq(psd_dict, target_freqs):\n",
    "    \"\"\"\n",
    "    Resample PSD values in a dictionary to align with a common set of frequency points.\n",
    "\n",
    "    Parameters:\n",
    "    - psd_dict: Dictionary containing \"freq\" and \"psd\" keys.\n",
    "    - target_freqs: 1D numpy array of target frequency points for the resampling.\n",
    "\n",
    "    Returns:\n",
    "    - Resampled PSD values aligned with target_freqs.\n",
    "    \"\"\"\n",
    "    resampled_psds = []\n",
    "\n",
    "    for freq, psd in zip(psd_dict[\"freq\"], psd_dict[\"psd\"]):\n",
    "        # Create an interpolation function based on the original freq and psd\n",
    "        interp_func = interp1d(\n",
    "            freq, psd, kind=\"linear\", bounds_error=False, fill_value=0\n",
    "        )\n",
    "        # Use this function to calculate the PSD values at the target frequencies\n",
    "        resampled_psd = interp_func(target_freqs)\n",
    "        resampled_psds.append(resampled_psd)\n",
    "\n",
    "    return np.array(resampled_psds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_sem(data):\n",
    "    \"\"\"Calculate the mean and standard error of the mean (SEM) of the data.\"\"\"\n",
    "    mean = np.mean(data, axis=0)\n",
    "    sem = np.std(data, axis=0, ddof=1) / np.sqrt(data.shape[0])\n",
    "    return mean, sem\n",
    "\n",
    "\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"Calculate the t-distribution based confidence interval for the given data.\"\"\"\n",
    "    sem = np.std(data, axis=0, ddof=1) / np.sqrt(data.shape[0])\n",
    "    df = data.shape[0] - 1  # Degrees of freedom\n",
    "    multiplier = t.ppf((1 + confidence) / 2.0, df)\n",
    "    return sem * multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the PSD data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6), sharey=True)\n",
    "\n",
    "# Define target frequencies for resampling\n",
    "target_freqs = np.linspace(0, 0.1, num=1000)\n",
    "\n",
    "for i, key in enumerate(psd_data.keys()):\n",
    "    # Resample and calculate mean and confidence interval for moving and immobile data\n",
    "    moving_resampled_psds = resample_psd_to_common_freq(\n",
    "        {\n",
    "            \"freq\": psd_data[key][\"moving\"][\"freq\"],\n",
    "            \"psd\": psd_data[key][\"moving\"][\"psd\"],\n",
    "        },\n",
    "        target_freqs,\n",
    "    )\n",
    "    notmoving_resampled_psds = resample_psd_to_common_freq(\n",
    "        {\n",
    "            \"freq\": psd_data[key][\"immobile\"][\"freq\"],\n",
    "            \"psd\": psd_data[key][\"immobile\"][\"psd\"],\n",
    "        },\n",
    "        target_freqs,\n",
    "    )\n",
    "\n",
    "    mean_moving_resampled_psd, sem_moving_resampled_psd = calculate_mean_sem(\n",
    "        moving_resampled_psds\n",
    "    )\n",
    "    mean_notmoving_resampled_psd, sem_notmoving_resampled_psd = calculate_mean_sem(\n",
    "        notmoving_resampled_psds\n",
    "    )\n",
    "\n",
    "    # Calculate the confidence interval for the mean PSD values\n",
    "    ci_moving_resampled_psd = confidence_interval(moving_resampled_psds)\n",
    "    ci_notmoving_resampled_psd = confidence_interval(notmoving_resampled_psds)\n",
    "\n",
    "    # Plot mean PSD for moving and not moving\n",
    "    axes[i].plot(\n",
    "        target_freqs,\n",
    "        mean_moving_resampled_psd,\n",
    "        label=\"Moving Average PSD\",\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        target_freqs,\n",
    "        mean_notmoving_resampled_psd,\n",
    "        label=\"Not Moving Average PSD\",\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "    # Add shaded confidence interval around the mean PSD\n",
    "    axes[i].fill_between(\n",
    "        target_freqs,\n",
    "        mean_moving_resampled_psd - ci_moving_resampled_psd,\n",
    "        mean_moving_resampled_psd + ci_moving_resampled_psd,\n",
    "        color=\"blue\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[i].fill_between(\n",
    "        target_freqs,\n",
    "        mean_notmoving_resampled_psd - ci_notmoving_resampled_psd,\n",
    "        mean_notmoving_resampled_psd + ci_notmoving_resampled_psd,\n",
    "        color=\"red\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    axes[i].set_title(\n",
    "        f\"Average PSD with 95% Confidence Intervals: {key.capitalize()} (Moving vs Not Moving)\"\n",
    "    )\n",
    "    axes[i].set_xlabel(\"Frequency (Hz)\")\n",
    "    axes[i].grid(True)\n",
    "    axes[i].set_yscale(\"log\")\n",
    "\n",
    "axes[0].set_ylabel(\"Power Spectral Density\")\n",
    "axes[0].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
