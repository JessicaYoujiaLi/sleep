{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis between dendritic and somatic signals. \n",
    "\n",
    "* 10/31/2024 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.classes.suite2p_class import Suite2p as s2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sima_folders = [\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11c5/8_2/TSeries-08022024-1036-001/TSeries-08022024-1036-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11c5/8_2/TSeries-08022024-1036-002/TSeries-08022024-1036-002.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b2/6_17/TSeries-06172024-0946-001/TSeries-06172024-0946-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b2/6_17/TSeries-06172024-0946-003/TSeries-06172024-0946-003.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/6_17/TSeries-06172024-0946-001/TSeries-06172024-0946-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/7_31/TSeries-07312024-1030-002/TSeries-07312024-1030-002.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/8_3/TSeries-08022024-1036-001/TSeries-08022024-1036-001.sima/\",\n",
    "    \"/data2/gergely/invivo_DATA/sleep/dock11b1/8_3/TSeries-08022024-1036-002/TSeries-08022024-1036-002.sima/\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks = {}\n",
    "planes = {0: \"dendrites\", 1: \"soma\"}\n",
    "for folder in sima_folders:\n",
    "    for plane, plane_name in planes.items():\n",
    "        s2p_data = s2p(join(folder, \"suite2p\"))\n",
    "        spikes = s2p_data.get_spikes(plane=plane)\n",
    "        # z scoring\n",
    "        zscored_spikes = zscore(spikes, axis=1)\n",
    "\n",
    "        # Add the z-scored data to the dictionary\n",
    "        if plane_name not in spks:\n",
    "            spks[plane_name] = []  # Initialize a list for each plane\n",
    "        spks[plane_name].append(zscored_spikes)\n",
    "\n",
    "mob_immobs = []\n",
    "for folder in sima_folders:\n",
    "    data = join(folder, \"behavior\", \"mobility_immobility.json\")\n",
    "    with open(data, \"r\") as f:\n",
    "        mob_immobs.append(np.array(json.load(f)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_length_calculator(\n",
    "    data: pd.DataFrame, state_column: str, state_value: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the length, start, and stop indices of intervals for a\n",
    "      specific state.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame containing interval data.\n",
    "        state_column (str): Column name indicating the state for each interval.\n",
    "        state_value (int): The value of the state to filter intervals by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns for the interval number ('n'),\n",
    "        the start index, the stop index, and the length of each interval of\n",
    "        the specified state.\n",
    "    \"\"\"\n",
    "    # Ensure data is not altered outside the function\n",
    "    data = data.copy()\n",
    "\n",
    "    # Convert the state column to ensure compatibility\n",
    "    data[state_column] = data[state_column].astype(int)\n",
    "\n",
    "    # Detect changes to and from the target state\n",
    "    is_target_state = data[state_column] == state_value\n",
    "    starts = is_target_state & (~is_target_state.shift(fill_value=False))\n",
    "    stops = (~is_target_state) & is_target_state.shift(fill_value=False)\n",
    "\n",
    "    # Prepare for data accumulation\n",
    "    rows = []\n",
    "\n",
    "    # Iterate over starts\n",
    "    for start in data[starts].index:\n",
    "        # Find the corresponding stop\n",
    "        stop = data[stops & (data.index > start)].index.min()\n",
    "        # If there's no corresponding stop, use the last index\n",
    "        if not pd.isna(stop):\n",
    "            stop -= 1\n",
    "        else:\n",
    "            stop = data.index[-1]\n",
    "\n",
    "        length = stop - start + 1\n",
    "        rows.append({\"start\": start, \"stop\": stop, \"length\": length})\n",
    "\n",
    "    # Create DataFrame from accumulated rows\n",
    "    result = pd.DataFrame(rows)\n",
    "\n",
    "    # Add interval numbers\n",
    "    result.insert(0, \"n\", range(1, len(result) + 1))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply interval_length_calculator to each mobility array\n",
    "def calculate_intervals_for_mobility_data(mob_immob_data, state_value=1):\n",
    "    \"\"\"\n",
    "    Calculate intervals for the specified mobility state using interval_length_calculator.\n",
    "\n",
    "    Parameters:\n",
    "    - mob_immob_data: List of numpy arrays containing mobility data (1 for moving, 0 for immobile)\n",
    "    - state_value: State to filter intervals by (1 for moving, 0 for immobile)\n",
    "\n",
    "    Returns:\n",
    "    - A list of DataFrames, each containing intervals of the specified state for a particular recording.\n",
    "    \"\"\"\n",
    "    interval_results = []\n",
    "\n",
    "    for idx, mobility_array in enumerate(mob_immob_data):\n",
    "        # Convert numpy array to DataFrame for compatibility with interval_length_calculator\n",
    "        mobility_df = pd.DataFrame({\"state\": mobility_array})\n",
    "\n",
    "        # Calculate intervals using the provided function\n",
    "        intervals_df = interval_length_calculator(\n",
    "            mobility_df, state_column=\"state\", state_value=state_value\n",
    "        )\n",
    "\n",
    "        # Store the results with an additional column indicating the recording\n",
    "        intervals_df[\"recording\"] = f\"folder_{idx + 1}\"\n",
    "        interval_results.append(intervals_df)\n",
    "\n",
    "    return interval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate moving and immobile intervals\n",
    "moving_intervals = calculate_intervals_for_mobility_data(mob_immobs, state_value=1)\n",
    "immobile_intervals = calculate_intervals_for_mobility_data(mob_immobs, state_value=0)\n",
    "\n",
    "# Combine all interval results into one DataFrame for moving and one for immobile\n",
    "all_moving_intervals_df = pd.concat(moving_intervals, ignore_index=True)\n",
    "all_immobile_intervals_df = pd.concat(immobile_intervals, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_moving_intervals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_immobile_spikes = {}\n",
    "\n",
    "# Assuming `spks` is a dictionary with keys ('dendrites', 'soma') and values being lists of arrays\n",
    "# Assuming `mob_immobs` is a list of mobility data arrays, one for each spike array in `spks`\n",
    "for key, spk_list in spks.items():\n",
    "    moving_spikes_list = []\n",
    "    immobile_spikes_list = []\n",
    "\n",
    "    for spk, mob_immob in zip(spk_list, mob_immobs):\n",
    "        try:\n",
    "            # Convert spk and mob_immob to numpy arrays if they are lists\n",
    "            spk = np.array(spk) if isinstance(spk, list) else spk\n",
    "            mob_immob = (\n",
    "                np.array(mob_immob) if isinstance(mob_immob, list) else mob_immob\n",
    "            )\n",
    "\n",
    "            print(spk.shape, mob_immob.shape)\n",
    "\n",
    "            # Check if shapes are mismatched\n",
    "            if spk.shape[1] != mob_immob.shape[0]:\n",
    "                print(\"shapes mismatched\")\n",
    "\n",
    "                # Create an interpolation function for mob_immob\n",
    "                x = np.linspace(0, 1, mob_immob.shape[0])\n",
    "                f = interp1d(x, mob_immob, kind=\"linear\")\n",
    "\n",
    "                # Create a new x array matching the spk shape and interpolate\n",
    "                new_x = np.linspace(0, 1, spk.shape[1])\n",
    "                mob_immob_interpolated = f(new_x)\n",
    "\n",
    "                # Convert interpolated values to boolean if necessary\n",
    "                mob_immob_interpolated = (\n",
    "                    mob_immob_interpolated >= 0.5\n",
    "                )  # Adjust this threshold as needed\n",
    "            else:\n",
    "                mob_immob_interpolated = mob_immob\n",
    "\n",
    "            # Split spikes into moving and immobile based on mobility data\n",
    "            moving_spikes = spk[:, mob_immob_interpolated == 1]\n",
    "            immobile_spikes = spk[:, mob_immob_interpolated != 1]\n",
    "\n",
    "            # Append the results to the respective lists\n",
    "            moving_spikes_list.append(moving_spikes)\n",
    "            immobile_spikes_list.append(immobile_spikes)\n",
    "\n",
    "        except ValueError as e:  # Adjust exception type if needed\n",
    "            print(f\"Error processing spike and mobility data for key '{key}': {e}\")\n",
    "            # Handle or log the error appropriately\n",
    "\n",
    "    # Store the results in the `moving_immobile_spikes` dictionary\n",
    "    moving_immobile_spikes[key] = {\n",
    "        \"moving_spikes\": moving_spikes_list,\n",
    "        \"immobile_spikes\": immobile_spikes_list,\n",
    "    }\n",
    "\n",
    "# Now `moving_immobile_spikes` contains the keys from the input dictionary `spks`,\n",
    "# with each key having a dictionary of both \"moving_spikes\" and \"immobile_spikes\" lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mob_immobs = [\n",
    "    filter_long_intervals(mob_immob, min_length=100) for mob_immob in mob_immobs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mob_immobs[5])\n",
    "plt.plot(filtered_mob_immobs[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store correlation results\n",
    "correlation_results = {\"moving\": [], \"immobile\": []}\n",
    "\n",
    "# Loop over all the folders and calculate correlations\n",
    "for moving_spikes_d, immobile_spikes_d, moving_spikes_s, immobile_spikes_s in zip(\n",
    "    moving_immobile_spikes[\"dendrites\"][\"moving_spikes\"],\n",
    "    moving_immobile_spikes[\"dendrites\"][\"immobile_spikes\"],\n",
    "    moving_immobile_spikes[\"soma\"][\"moving_spikes\"],\n",
    "    moving_immobile_spikes[\"soma\"][\"immobile_spikes\"],\n",
    "):\n",
    "    # Correlate for moving spikes\n",
    "    if moving_spikes_d.shape[1] > 0 and moving_spikes_s.shape[1] > 0:\n",
    "        # Calculate Pearson correlation across corresponding time points\n",
    "        moving_correlation = np.corrcoef(moving_spikes_d, moving_spikes_s, rowvar=False)\n",
    "        correlation_results[\"moving\"].append(moving_correlation)\n",
    "\n",
    "    # Correlate for immobile spikes\n",
    "    if immobile_spikes_d.shape[1] > 0 and immobile_spikes_s.shape[1] > 0:\n",
    "        # Calculate Pearson correlation across corresponding time points\n",
    "        immobile_correlation = np.corrcoef(\n",
    "            immobile_spikes_d, immobile_spikes_s, rowvar=False\n",
    "        )\n",
    "        correlation_results[\"immobile\"].append(immobile_correlation)\n",
    "\n",
    "# Now `correlation_results` contains the correlation matrices for moving and immobile periods.\n",
    "# You can further process or visualize these results as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
